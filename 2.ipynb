{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a8b6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2699142395739956e-08\n",
      "R-squared: 0.9999999936504288\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        if depth == self.max_depth or n_samples <= 1:\n",
    "            return np.mean(y)\n",
    "        else:\n",
    "            # Find the best split\n",
    "            best_feature = None\n",
    "            best_split = None\n",
    "            best_loss = float('inf')\n",
    "            for feature in range(n_features):\n",
    "                unique_values = np.unique(X[:, feature])\n",
    "                for value in unique_values:\n",
    "                    left_mask = X[:, feature] <= value\n",
    "                    right_mask = X[:, feature] > value\n",
    "                    left_y = y[left_mask]\n",
    "                    right_y = y[right_mask]\n",
    "                    if len(left_y) > 0 and len(right_y) > 0:\n",
    "                        loss = np.sum((left_y - np.mean(left_y)) ** 2) + np.sum((right_y - np.mean(right_y)) ** 2)\n",
    "                        if loss < best_loss:\n",
    "                            best_loss = loss\n",
    "                            best_feature = feature\n",
    "                            best_split = value\n",
    "\n",
    "            if best_feature is not None:\n",
    "                left_mask = X[:, best_feature] <= best_split\n",
    "                right_mask = X[:, best_feature] > best_split\n",
    "                left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "                right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "                return best_feature, best_split, left_tree, right_tree\n",
    "            else:\n",
    "                return np.mean(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        if isinstance(tree, tuple):\n",
    "            feature, split, left_tree, right_tree = tree\n",
    "            if x[feature] <= split:\n",
    "                return self._predict_tree(x, left_tree)\n",
    "            else:\n",
    "                return self._predict_tree(x, right_tree)\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize residuals to the target values\n",
    "        residuals = y.astype(float)\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            # Fit a decision tree to the residuals\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            \n",
    "            # Update residuals using the predictions of the tree\n",
    "            predictions = tree.predict(X)\n",
    "            residuals -= self.learning_rate * predictions\n",
    "            \n",
    "            # Add the tree to the ensemble\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions by summing predictions of all trees\n",
    "        predictions = np.zeros(len(X))\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return predictions\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    numerator = np.sum((y_true - y_pred) ** 2)\n",
    "    denominator = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "# Example dataset\n",
    "X_train = np.array([[1], [2], [3], [4], [5]])\n",
    "y_train = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Initialize and train gradient boosting regressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_regressor.predict(X_train)\n",
    "\n",
    "# Evaluate performance\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "r2 = r_squared(y_train, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9b24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
